{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmJ1Mu3rtQKd"
      },
      "source": [
        "\n",
        "```\n",
        "@data{DVN/DBW86T_2018,\n",
        "author = {Tschandl, Philipp},\n",
        "publisher = {Harvard Dataverse},\n",
        "title = {{The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions}},\n",
        "UNF = {UNF:6:KCZFcBLiFE5ObWcTc2ZBOA==},\n",
        "year = {2018},\n",
        "version = {V4},\n",
        "doi = {10.7910/DVN/DBW86T},\n",
        "url = {https://doi.org/10.7910/DVN/DBW86T}\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWecX2atzKd"
      },
      "source": [
        "The HAM10000 dataset served as the training set for the ISIC 2018 challenge (Task 3), with the same sources contributing the majority of the validation- and test-set as well. The test-set images are available herein as ISIC2018_Task3_Test_Images.zip (1511 images), the ground-truth in the same format as the HAM10000 data (public since 2023) is available as ISIC2018_Task3_Test_GroundTruth.csv.. The ISIC-Archive also provides the challenge images and metadata (training, validation, test) at their \"ISIC Challenge Datasets\" page.\n",
        "\n",
        "https://challenge.isic-archive.com/data/#2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-15T19:19:28.577164Z",
          "iopub.status.busy": "2023-06-15T19:19:28.576765Z",
          "iopub.status.idle": "2023-06-15T19:19:43.581695Z",
          "shell.execute_reply": "2023-06-15T19:19:43.580412Z",
          "shell.execute_reply.started": "2023-06-15T19:19:28.577130Z"
        },
        "id": "y0Iwdk7rsdKY",
        "outputId": "0082581e-f4ed-4966-88fe-2f4daf203701",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opendatasets in /opt/conda/lib/python3.10/site-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.28.2)\n",
            "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-15T19:20:28.947034Z",
          "iopub.status.busy": "2023-06-15T19:20:28.945979Z",
          "iopub.status.idle": "2023-06-15T19:21:32.611150Z",
          "shell.execute_reply": "2023-06-15T19:21:32.609856Z",
          "shell.execute_reply.started": "2023-06-15T19:20:28.946985Z"
        },
        "id": "48u2m-BlxShV",
        "outputId": "c82481a2-61df-47fc-d852-06e242ff5449",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading skin-cancer-mnist-ham10000.zip to ./skin-cancer-mnist-ham10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.20G/5.20G [00:27<00:00, 204MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# upload kaggle.json and the data will automatically be read\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\", force=True)\n",
        "\n",
        "path = \"skin-cancer-mnist-ham10000/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.291305Z",
          "iopub.status.idle": "2023-06-15T19:19:16.292079Z",
          "shell.execute_reply": "2023-06-15T19:19:16.291843Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.291819Z"
        },
        "id": "NKq2LpoIyXuW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "meta = pd.read_csv(path + 'HAM10000_metadata.csv')\n",
        "meta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.293493Z",
          "iopub.status.idle": "2023-06-15T19:19:16.294281Z",
          "shell.execute_reply": "2023-06-15T19:19:16.294022Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.293999Z"
        },
        "id": "jsD__EvGlZDv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# description from ISIC\n",
        "lesion_types = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "lesion_type_short = {\n",
        "    'nv': 0,\n",
        "    'mel': 1,\n",
        "    'bkl': 2,\n",
        "    'bcc': 3,\n",
        "    'akiec': 4,\n",
        "    'vasc': 5,\n",
        "    'df': 6\n",
        "}\n",
        "\n",
        "lesion_names = ['Melanocytic nevi','Melanoma','Benign keratosis-like lesions ',\n",
        "               'Basal cell carcinoma','Actinic keratoses','Vascular lesions',\n",
        "               'Dermatofibroma']\n",
        "\n",
        "lesion_names_short = ['nv','mel','bkl','bcc','akiec','vasc','df']\n",
        "\n",
        "meta['lesion_type']=meta['dx'].map(lesion_types)\n",
        "meta['lesion_type_short'] = meta['dx'].map(lesion_type_short)\n",
        "\n",
        "print('Total number of images %i' %(len(meta)))\n",
        "\n",
        "meta['lesion_type'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNNZH_OxnPrx"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.297841Z",
          "iopub.status.idle": "2023-06-15T19:19:16.298615Z",
          "shell.execute_reply": "2023-06-15T19:19:16.298375Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.298353Z"
        },
        "id": "eWRRSKvAmLJf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# retrieve images\n",
        "images = np.array(meta['image_id'])\n",
        "HAM_part1 = path + 'HAM10000_images_part_1/' + str(images[1]) + '.jpg'\n",
        "\n",
        "import cv2\n",
        "from cv2 import imread, resize\n",
        "\n",
        "img = imread(HAM_part1)\n",
        "resized_img = resize(img,(100,100))\n",
        "\n",
        "# show one exampe image\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img[:,:,::-1])\n",
        "plt.title('Original image')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(resized_img[:,:,::-1])\n",
        "plt.title('Resized image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.300007Z",
          "iopub.status.idle": "2023-06-15T19:19:16.300782Z",
          "shell.execute_reply": "2023-06-15T19:19:16.300539Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.300517Z"
        },
        "id": "si5XEkCymLOH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# augmenting images to reduce class imbalance\n",
        "# number allows to specify how many augmented versions of the\n",
        "# original image shall be produced\n",
        "def augment(image, number:int = 5):\n",
        "    # produce new images by rotating of flipping the original one\n",
        "    # this helps to increase the dimension of the dataset, avoiding overfitting of a single class\n",
        "    if number == 1:\n",
        "      a = cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n",
        "      return a\n",
        "\n",
        "    if number == 2:\n",
        "      a = cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n",
        "      b = cv2.rotate(image,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "      return a, b\n",
        "\n",
        "    if number == 3:\n",
        "      a = cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n",
        "      b = cv2.rotate(image,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "      c = cv2.rotate(image,cv2.ROTATE_180)\n",
        "      return a, b, c\n",
        "    if number == 4:\n",
        "      a = cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n",
        "      b = cv2.rotate(image,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "      c = cv2.rotate(image,cv2.ROTATE_180)\n",
        "      d = cv2.flip(img2,0)\n",
        "      return a, b, c, d\n",
        "    if number == 5:\n",
        "      a = cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n",
        "      b = cv2.rotate(image,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "      c = cv2.rotate(image,cv2.ROTATE_180)\n",
        "      d = cv2.flip(image,0)\n",
        "      e = cv2.flip(image,1)\n",
        "      return a, b, c, d, e\n",
        "\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "new_img = augment(resized_img)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(resized_img[:,:,::-1])\n",
        "for i in range(5):\n",
        "    plt.subplot(2,3,2+i)\n",
        "    plt.imshow(new_img[i][:,:,::-1])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.302209Z",
          "iopub.status.idle": "2023-06-15T19:19:16.302967Z",
          "shell.execute_reply": "2023-06-15T19:19:16.302741Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.302718Z"
        },
        "id": "DHjFOk75mLW7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# function for importing images from the two folders\n",
        "\n",
        "def image_importer(path, append=True, X:list=[], y:list=[]):\n",
        "  dir_list = os.listdir(path)\n",
        "\n",
        "\n",
        "  if append:\n",
        "    # allows for adding images to established containers\n",
        "    pass\n",
        "  else:\n",
        "    # initialize empty containers for predictor and target images\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "  for i in range(len(dir_list)):\n",
        "      fname_image = dir_list[i]\n",
        "      fname_id = fname_image.replace('.jpg','')\n",
        "\n",
        "      # features|predictors\n",
        "      folder = path + str(fname_image)\n",
        "      img = imread(folder)\n",
        "      resized_img = resize(img,(100, 100))\n",
        "      X.append(resized_img)\n",
        "\n",
        "      # targets|predicted\n",
        "      output = np.array(meta[meta['image_id'] == fname_id].lesion_type_short)\n",
        "      y.append(output[0])\n",
        "\n",
        "      # add more images for class between 1-6, by rotation and flipping\n",
        "      if output != 0:\n",
        "          new_img = augment(resized_img)\n",
        "          for i in range(5):\n",
        "              X.append(new_img[i])\n",
        "              y.append(output[0])\n",
        "\n",
        "      # print progress\n",
        "      if append==False and i % int(100) == 0: # (not append)\n",
        "         # print(i,'images loaded')\n",
        "         # \"{char_start:filler<right^center>left-ragged[f_loat,d_ecimal, s_tring]}\".format(...)\n",
        "          print(\"{0:-<7d}\".format(i), \"images loaded\") # d stands for decimal\n",
        "      elif append and (len(dir_list)+i) % int(100) == 0:\n",
        "        #print((len(X)+i), \"images loaded\")\n",
        "          print(\"{0:-<7d}\".format(len(dir_list)+i), \"images loaded\")\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.304344Z",
          "iopub.status.idle": "2023-06-15T19:19:16.305153Z",
          "shell.execute_reply": "2023-06-15T19:19:16.304888Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.304864Z"
        },
        "id": "9yPayYEVmLZn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "part1 = path + 'HAM10000_images_part_1/'\n",
        "part2 = path + 'HAM10000_images_part_2/'\n",
        "\n",
        "# importing the images and storing them the feature variable X\n",
        "X, y = image_importer(part1, append=False)\n",
        "# appending the second part of HAM10000\n",
        "X, y = image_importer(part2, append=True, X=X, y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.306613Z",
          "iopub.status.idle": "2023-06-15T19:19:16.307394Z",
          "shell.execute_reply": "2023-06-15T19:19:16.307163Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.307141Z"
        },
        "id": "3Y03JOUfx6wc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# data shall be comprised of 10_015 * 6 = 60090 images\n",
        "# X and y are still lists\n",
        "print(len(X) , len(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9oLBqDzW2UK"
      },
      "source": [
        "\\begin{array}{|c|c|} \\hline\n",
        "\\text{Lesion Type} & \\text{Observations} & \\text{Augmentation} & \\text{Total} \\\\ \\hline\n",
        "%\\text{Total number of images} & 10015 & & \\\\\n",
        "\\text{Melanocytic nevy} & 6705 & None & 6705  \\\\\n",
        "\\text{Melanoma} & 1113 & \\times 6 & 6678 \\\\\n",
        "\\text{Benign keratosis-like lesions} & 1099 & \\times 6 & 6594 \\\\\n",
        "\\text{Basal cell carcinoma} & 514 & \\times 6 & 3084 \\\\\n",
        "\\text{Actinic keratoses} & 327 & \\times 6 & 1962 \\\\\n",
        "\\text{Vascular lesions} & 142 & \\times 6 & 852 \\\\\n",
        "\\text{Dermatofibroma} & 115 & \\times 6 & 690 \\\\ \\hline\n",
        "\\text{Σ} & 10015  &  & 26565 \\\\ \\hline\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.308810Z",
          "iopub.status.idle": "2023-06-15T19:19:16.309659Z",
          "shell.execute_reply": "2023-06-15T19:19:16.309377Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.309352Z"
        },
        "id": "EIBiUl3RxHus",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# converting image data to\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# convert 7 classes into categorical encodings\n",
        "y_train = to_categorical(y, num_classes=7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.311162Z",
          "iopub.status.idle": "2023-06-15T19:19:16.311930Z",
          "shell.execute_reply": "2023-06-15T19:19:16.311705Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.311681Z"
        },
        "id": "KgXbNuprHX4T",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# matrix dimensions\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYdzORihJd8L"
      },
      "source": [
        "X has 4 dimensions:\n",
        "\n",
        "+ Dimension 1: It has a size of 26565, indicating that X contains 26565 elements along this dimension. This could represent the number of samples or data points in your dataset.\n",
        "\n",
        "+ Dimension 2: It has a size of 100, meaning that each sample in X has a length or height of 100 units.\n",
        "\n",
        "+ Dimension 3: It also has a size of 100, indicating that each sample in X has a width of 100 units.\n",
        "\n",
        "+ Dimension 4: It has a size of 3, suggesting that each element in the X array is a 3-channel image. The three channels typically correspond to the red, green, and blue color channels, which form an RGB image.\n",
        "\n",
        "+ So, in summary, X is a 4-dimensional array where the first dimension represents the number of samples, and the last three dimensions represent the height, width, and number of channels (in this case, 3 for RGB) of each sample image, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.313356Z",
          "iopub.status.idle": "2023-06-15T19:19:16.314134Z",
          "shell.execute_reply": "2023-06-15T19:19:16.313891Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.313867Z"
        },
        "id": "txomHDX1xHxm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split in 80% training and 20% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.33, random_state=50, stratify=y)\n",
        "\n",
        "\n",
        "print('Train dataset shape', X_train.shape)\n",
        "print('Test dataset shape', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.315545Z",
          "iopub.status.idle": "2023-06-15T19:19:16.316336Z",
          "shell.execute_reply": "2023-06-15T19:19:16.316092Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.316067Z"
        },
        "id": "w84-OWfHxH09",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 7, figsize=(30, 30))\n",
        "for i in range(7):\n",
        "    ax[i].set_axis_off()\n",
        "    ax[i].imshow(X_train[i]) #, cmap=\"Accent\"\n",
        "    ax[i].set_title(lesion_names[np.argmax(y_train[i])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1k9sQ0BcM8Z"
      },
      "source": [
        "The np.argmax function is a NumPy function that returns the index of the maximum value in an array. In the provided code, np.argmax(y_train[i]) is used to find the index of the maximum value in the i-th element of the y_train array. This index corresponds to the predicted class label for the i-th image in the dataset.\n",
        "\n",
        "Regarding the blueish color tone in the plots, it is likely because the default colormap used by imshow in matplotlib is 'viridis', which is a colormap that ranges from blue to yellow. This colormap is used to represent the intensity values of the image pixels. However, without the complete code, it is difficult to determine the exact reason for the blueish color tone. It could also be due to specific image processing or normalization applied to the images before plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.317638Z",
          "iopub.status.idle": "2023-06-15T19:19:16.318428Z",
          "shell.execute_reply": "2023-06-15T19:19:16.318192Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.318155Z"
        },
        "id": "TwoDGRVwdHS_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "meta[\"lesion_type_short\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.319798Z",
          "iopub.status.idle": "2023-06-15T19:19:16.320590Z",
          "shell.execute_reply": "2023-06-15T19:19:16.320365Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.320341Z"
        },
        "id": "FivY_QPkdGJY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "y_id = np.array(meta[\"lesion_type_short\"])\n",
        "\n",
        "# compute weights for the loss function, because the problem is unbalanced\n",
        "class_weights = np.around(compute_class_weight(class_weight='balanced',classes=np.unique(y_id),y=y), 2)\n",
        "class_weights = dict(zip(np.unique(y_id),class_weights))\n",
        "\n",
        "print('The problem is unbalanced. We need to provide class_weights ')\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebtOY11jGE1L"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8omGSoHsriCb"
      },
      "source": [
        "# CNN in VGG style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.333716Z",
          "iopub.status.idle": "2023-06-15T19:19:16.334527Z",
          "shell.execute_reply": "2023-06-15T19:19:16.334279Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.334255Z"
        },
        "id": "nliUnT9Sqd0T",
        "outputId": "bcf1f13d-759f-4744-d049-d11813d7b994",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 47, 47, 64)        9472      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 47, 47, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 12, 12, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 8, 8, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 6, 6, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 4, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              33558528  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,654,727\n",
            "Trainable params: 56,650,759\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
        "    BatchNormalization, concatenate, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dropout, Activation\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Input\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(100, 100, 3))\n",
        "\n",
        "deep = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), activation='relu')(input_layer)\n",
        "deep = BatchNormalization()(deep)\n",
        "deep = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(deep)\n",
        "\n",
        "deep = Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding=\"same\")(deep)\n",
        "deep = BatchNormalization()(deep)\n",
        "deep = MaxPool2D(pool_size=(3, 3), strides=(1, 1))(deep)\n",
        "\n",
        "deep = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\")(deep)\n",
        "deep = BatchNormalization()(deep)\n",
        "deep = MaxPool2D(pool_size=(3, 3), strides=(1, 1))(deep)\n",
        "\n",
        "deep = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\")(deep)\n",
        "deep = BatchNormalization()(deep)\n",
        "\n",
        "deep = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\")(deep)\n",
        "deep = BatchNormalization()(deep)\n",
        "deep = MaxPool2D(pool_size=(3, 3), strides=(1, 1))(deep)\n",
        "\n",
        "deep = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\")(deep)\n",
        "deep = BatchNormalization()(deep)\n",
        "deep = MaxPool2D(pool_size=(3, 3), strides=(1, 1))(deep)\n",
        "\n",
        "deep = Flatten()(deep)\n",
        "\n",
        "deep = Dense(4096, activation='relu')(deep)\n",
        "deep = Dropout(0.5)(deep)\n",
        "\n",
        "deep = Dense(4096, activation='relu')(deep)\n",
        "deep = Dropout(0.5)(deep)\n",
        "\n",
        "output = Dense(7, activation='softmax')(deep)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.335950Z",
          "iopub.status.idle": "2023-06-15T19:19:16.336742Z",
          "shell.execute_reply": "2023-06-15T19:19:16.336517Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.336494Z"
        },
        "id": "uAfPCDMoxH9l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(patience=100, monitor='val_accuracy')\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath='CNN.h5',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='auto',\n",
        "                                            save_best_only=True,\n",
        "                                            verbose=1)\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
        "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history=model.fit(datagen.flow(X_train,y_train), epochs=epochs,\n",
        "                  batch_size=batch_size, shuffle=True,\n",
        "                  callbacks=[early_stopping_monitor,\n",
        "                             model_checkpoint_callback],\n",
        "                  validation_data=(X_test, y_test), class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.338128Z",
          "iopub.status.idle": "2023-06-15T19:19:16.338873Z",
          "shell.execute_reply": "2023-06-15T19:19:16.338658Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.338635Z"
        },
        "id": "DIvPQdPZsGZI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Training Loss\")\n",
        "plt.plot(range(1, len(val_loss) + 1), val_loss, label=\"Validation Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "#plt.title('Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.340258Z",
          "iopub.status.idle": "2023-06-15T19:19:16.341024Z",
          "shell.execute_reply": "2023-06-15T19:19:16.340799Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.340776Z"
        },
        "id": "-kr3wNWVgDJS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.342843Z",
          "iopub.status.idle": "2023-06-15T19:19:16.343715Z",
          "shell.execute_reply": "2023-06-15T19:19:16.343467Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.343443Z"
        },
        "id": "jhpTjGusgBgz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.345201Z",
          "iopub.status.idle": "2023-06-15T19:19:16.345927Z",
          "shell.execute_reply": "2023-06-15T19:19:16.345714Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.345692Z"
        },
        "id": "NIaaKQIUgLJK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "total = 0\n",
        "accurate = 0\n",
        "accurateindex = []\n",
        "wrongindex = []\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
        "        accurate += 1\n",
        "        accurateindex.append(i)\n",
        "    else:\n",
        "        wrongindex.append(i)\n",
        "\n",
        "    total += 1\n",
        "\n",
        "print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
        "\n",
        "print('Accuracy:', round(accurate/total*100, 3), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.347384Z",
          "iopub.status.idle": "2023-06-15T19:19:16.348163Z",
          "shell.execute_reply": "2023-06-15T19:19:16.347924Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.347899Z"
        },
        "id": "6d9nkyF1gR0C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# compute predictions\n",
        "y_pred_prob = np.around(model.predict(X_test),3)\n",
        "y_pred = np.argmax(y_pred_prob,axis=1)\n",
        "\n",
        "y_test2 = np.argmax(y_test,axis=1)\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    index = i+100\n",
        "    plt.imshow(X_test[index,:,:,::-1])\n",
        "    label_exp = lesion_names[y_test2[index]]  #expected label\n",
        "    label_pred = lesion_names[y_pred[index]]  #predicted label\n",
        "    label_pred_prob = round(np.max(y_pred_prob[index])*100)\n",
        "    plt.title('Expected:'+str(label_exp)+'\\n Pred.:'+str(label_pred)+' ('+str(label_pred_prob)+'%)')\n",
        "plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('final_figure.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-15T19:19:16.349629Z",
          "iopub.status.idle": "2023-06-15T19:19:16.350488Z",
          "shell.execute_reply": "2023-06-15T19:19:16.350240Z",
          "shell.execute_reply.started": "2023-06-15T19:19:16.350214Z"
        },
        "trusted": true,
        "id": "ULqKwNDJafnf"
      },
      "outputs": [],
      "source": [
        "# manually saving the model\n",
        "model.save('CNN.h5',save_format='h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}